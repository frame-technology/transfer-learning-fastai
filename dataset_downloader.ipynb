{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Data Setup\n",
    "Run the following if you want to download the imdb reviews, process them into csvs, and upload them as your own Floydhub dataset. \n",
    "### NOTE: \n",
    "You'll likely need to run the train_test_split shuffling in CPU2 mode because there's more RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download\n",
    "Uncomment out the bottom lines if you haven't downloaded it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-19 00:41:46--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]  80.23M  9.74MB/s    in 7.9s    \n",
      "\n",
      "2018-10-19 00:41:54 (10.2 MB/s) - written to stdout [84125825/84125825]\n",
      "\n",
      "aclImdb\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH=Path('data/')\n",
    "DATA_PATH.mkdir(exist_ok=True)\n",
    "! wget -c http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -O - | tar -xz -C {DATA_PATH}\n",
    "! ls data/    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize format\n",
    "This is lifted straight from this notebook - https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/aclImdb/')\n",
    "\n",
    "CSV_PATH=Path('data/csv/')\n",
    "CSV_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imdb dataset has 3 classes. positive, negative and unsupervised(sentiment is unknown). There are 75k training reviews(12.5k pos, 12.5k neg, 50k unsup) There are 25k validation reviews(12.5k pos, 12.5k neg & no unsup)\n",
    "\n",
    "Refer to the README file in the imdb corpus for further information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['neg', 'pos']\n",
    "\n",
    "def get_texts(path):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(CLASSES):\n",
    "        for fname in (path/label).glob('*.*'):\n",
    "            texts.append(fname.open('r', encoding='utf-8').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts),np.array(labels)\n",
    "\n",
    "trn_texts,trn_labels = get_texts(PATH/'train')\n",
    "val_texts,val_labels = get_texts(PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 25000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts),len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['labels','text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a random permutation np array to shuffle the text reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "trn_idx = np.random.permutation(len(trn_texts))\n",
    "val_idx = np.random.permutation(len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 0, 2, 0, 2, 2, 2]),\n",
       " array([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_texts = trn_texts[trn_idx]\n",
    "val_texts = val_texts[val_idx]\n",
    "\n",
    "trn_labels = trn_labels[trn_idx]\n",
    "val_labels = val_labels[val_idx]\n",
    "trn_labels[:20], val_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas dataframe is used to store text data in a newly evolving standard format of label followed by text columns. This was influenced by a paper by Yann LeCun (LINK REQUIRED). Fastai adopts this new format for NLP datasets. In the case of IMDB, there is only one text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn[df_trn['labels']!=2].to_csv(CSV_PATH/'train_clas.csv', header=False, index=False)\n",
    "df_val.to_csv(CSV_PATH/'valid_clas.csv', header=False, index=False)\n",
    "\n",
    "(CSV_PATH/'classes.txt').open('w', encoding='utf-8').writelines(f'{o}\\n' for o in CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating the data for the Language Model(LM). The LM's goal is to learn the structure of the english language. It learns language by trying to predict the next word given a set of previous words(ngrams). Since the LM does not classify reviews, the labels can be ignored.\n",
    "\n",
    "The LM can benefit from all the textual data and there is no need to exclude the unsup/unclassified movie reviews.\n",
    "\n",
    "We first concat all the train(pos/neg/unsup = 75k) and test(pos/neg=25k) reviews into a big chunk of 100k reviews. And then we use sklearn splitter to divide up the 100k texts into 90% training and 10% validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,val_texts = train_test_split(\n",
    "    np.concatenate([trn_texts,val_texts]), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)\n",
    "\n",
    "df_trn.to_csv(CSV_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CSV_PATH/'valid.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's save these csvs as a dataset. Be sure to create this dataset using the same name below in Floyd's dataset tab. Don't forget your username in the data init path. First, let's copy the classes.txt over to this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n",
      "pos\n",
      "unsup\n"
     ]
    }
   ],
   "source": [
    "! cat {CSV_PATH}/classes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the pretrained wikitext language model\n",
    "Let's set this up as a separate data source for transfer learning later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d7affeaf654e03a7f0c1d091a702b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=221972701), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b450987c6f14feabf9f3a4516712219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1027972), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = CSV_PATH/'models'\n",
    "model_path.mkdir(exist_ok=True)\n",
    "url = 'http://files.fast.ai/models/wt103_v1/'\n",
    "download_url(f'{url}lstm_wt103.pth', model_path/'lstm_wt103.pth')\n",
    "download_url(f'{url}itos_wt103.pkl', model_path/'itos_wt103.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create a dataset with the name below before running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/floyd/home/data/csv\n",
      "Data source \"frame/imdb_reviews_wt103\" initialized in current directory\n",
      "\n",
      "    You can now upload your data to Floyd by:\n",
      "        floyd data upload\n",
      "    \n",
      "Compressing data...\n",
      "Making create request to server...\n",
      "Initializing upload...\n",
      "Uploading compressed data. Total upload size: 273.3MiB\n",
      "[================================] 286617730/286617730 - 00:00:18\n",
      "Removing compressed data...\n",
      "Upload finished.\n",
      "Waiting for server to unpack data.\n",
      "You can exit at any time and come back to check the status with:\n",
      "\tfloyd data upload -r\n",
      "Waiting for unpack......\n",
      "\n",
      "NAME\n",
      "-----------------------------------\n",
      "frame/datasets/imdb_reviews_wt103/1\n"
     ]
    }
   ],
   "source": [
    "%cd {CSV_PATH}\n",
    "username = 'frame'\n",
    "!floyd data init {username}/imdb_reviews_wt103\n",
    "!floyd data upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next up\n",
    "Finished! Now try running the '00_start_here' workspace to spin off jobs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
