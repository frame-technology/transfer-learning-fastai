{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai==1.0.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/0b/8a3364a29aaf880263d425c2f022c404026c1188780cf0a0eaae25cbd347/fastai-1.0.6-py3-none-any.whl (95kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 5.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (0.23.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (5.2.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (2.2.3)\n",
      "Collecting spacy>=2.0.16 (from fastai==1.0.6)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/39/288640f591b29aac6996c97ddfafc3262ae0be7513e06bc560921b112d7c/spacy-2.0.16-cp36-cp36m-manylinux1_x86_64.whl (23.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 23.3MB 2.6MB/s \n",
      "\u001b[?25hCollecting fastprogress>=0.1.10 (from fastai==1.0.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/78/460d7032fdba5579b5e8945cefba8aed7bb730a13da3bcf92ebd61866281/fastprogress-0.1.10-py3-none-any.whl\n",
      "Requirement already satisfied: torchvision-nightly in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (0.2.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (1.1.0)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (3.6.6)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (0.6)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (6.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (2.19.1)\n",
      "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (1.15.1)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/site-packages (from fastai==1.0.6) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/site-packages (from pandas->fastai==1.0.6) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/site-packages (from pandas->fastai==1.0.6) (2018.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib->fastai==1.0.6) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib->fastai==1.0.6) (2.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/site-packages (from matplotlib->fastai==1.0.6) (1.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib->fastai==1.0.6) (1.0.1)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/site-packages (from spacy>=2.0.16->fastai==1.0.6) (0.2.8.2)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=2.0.16->fastai==1.0.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/61/9b0520c28eb199a4b1ca667d96dd625bba003c14c75230195f9691975f85/cymem-2.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/site-packages (from spacy>=2.0.16->fastai==1.0.6) (0.4.3.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/site-packages (from spacy>=2.0.16->fastai==1.0.6) (0.9.6)\n",
      "Collecting regex==2018.01.10 (from spacy>=2.0.16->fastai==1.0.6)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f4/7146c3812f96fcaaf2d06ff6862582302626a59011ccb6f2833bb38d80f7/regex-2018.01.10.tar.gz (612kB)\n",
      "\u001b[K    100% |████████████████████████████████| 614kB 12.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/site-packages (from spacy>=2.0.16->fastai==1.0.6) (1.35)\n",
      "Collecting preshed<2.1.0,>=2.0.1 (from spacy>=2.0.16->fastai==1.0.6)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 22.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/site-packages (from spacy>=2.0.16->fastai==1.0.6) (0.28.0)\n",
      "Collecting thinc<6.13.0,>=6.12.0 (from spacy>=2.0.16->fastai==1.0.6)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/18/e320bfc57c20df39cc5ffa1915c7b5402a9038f290ddd85b5b72689bd57a/thinc-6.12.0-cp36-cp36m-manylinux1_x86_64.whl (1.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.9MB 14.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from torchvision-nightly->fastai==1.0.6) (4.25.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (4.3.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (0.7.4)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (0.12.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (4.3.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (39.1.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (1.0.15)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (4.6.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (2.2.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/site-packages (from ipython->fastai==1.0.6) (0.1.0)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->fastai==1.0.6) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->fastai==1.0.6) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->fastai==1.0.6) (2018.8.13)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->fastai==1.0.6) (2.7)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/site-packages (from jupyter->fastai==1.0.6) (5.3.1)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/site-packages (from jupyter->fastai==1.0.6) (5.2.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.6/site-packages (from jupyter->fastai==1.0.6) (5.6.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/site-packages (from jupyter->fastai==1.0.6) (7.4.0)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/site-packages (from jupyter->fastai==1.0.6) (4.4.1)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/site-packages (from jupyter->fastai==1.0.6) (4.8.2)\n",
      "Requirement already satisfied: msgpack>=0.3.0 in /usr/local/lib/python3.6/site-packages (from msgpack-numpy<0.4.4->spacy>=2.0.16->fastai==1.0.6) (0.5.6)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.0->spacy>=2.0.16->fastai==1.0.6) (1.10.11)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.0->spacy>=2.0.16->fastai==1.0.6) (0.9.0.1)\n",
      "Requirement already satisfied: parso>=0.3.0 in /usr/local/lib/python3.6/site-packages (from jedi>=0.10->ipython->fastai==1.0.6) (0.3.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/site-packages (from traitlets>=4.2->ipython->fastai==1.0.6) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython->fastai==1.0.6) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython->fastai==1.0.6) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==1.0.6) (2.10)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==1.0.6) (4.4.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==1.0.6) (1.4.2)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==1.0.6) (0.3.1)\n",
      "Requirement already satisfied: mistune>=0.7.4 in /usr/local/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==1.0.6) (0.8.3)\n",
      "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==1.0.6) (4.4.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==1.0.6) (2.1.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==1.0.6) (0.2.3)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/site-packages (from jupyter-console->jupyter->fastai==1.0.6) (5.2.3)\n",
      "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/site-packages (from notebook->jupyter->fastai==1.0.6) (5.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/site-packages (from notebook->jupyter->fastai==1.0.6) (0.3.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/site-packages (from notebook->jupyter->fastai==1.0.6) (0.8.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/site-packages (from notebook->jupyter->fastai==1.0.6) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.6/site-packages (from notebook->jupyter->fastai==1.0.6) (17.1.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/site-packages (from ipywidgets->jupyter->fastai==1.0.6) (3.4.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.0->spacy>=2.0.16->fastai==1.0.6) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/site-packages (from jinja2->nbconvert->jupyter->fastai==1.0.6) (1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/site-packages (from nbformat>=4.4->nbconvert->jupyter->fastai==1.0.6) (2.6.0)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /usr/local/lib/python3.6/site-packages (from bleach->nbconvert->jupyter->fastai==1.0.6) (1.0.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->jupyter->fastai==1.0.6) (0.5.1)\n",
      "Building wheels for collected packages: regex\n",
      "  Running setup.py bdist_wheel for regex ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/74/17/3f/c77bba99efd74ba1a19862c9dd97f4b6d735e2826721dc00ff\n",
      "Successfully built regex\n",
      "Installing collected packages: cymem, regex, preshed, thinc, spacy, fastprogress, fastai\n",
      "  Found existing installation: cymem 1.31.2\n",
      "    Uninstalling cymem-1.31.2:\n",
      "      Successfully uninstalled cymem-1.31.2\n",
      "  Found existing installation: regex 2017.4.5\n",
      "    Uninstalling regex-2017.4.5:\n",
      "      Successfully uninstalled regex-2017.4.5\n",
      "  Found existing installation: preshed 1.0.1\n",
      "    Uninstalling preshed-1.0.1:\n",
      "      Successfully uninstalled preshed-1.0.1\n",
      "  Found existing installation: thinc 6.10.3\n",
      "    Uninstalling thinc-6.10.3:\n",
      "      Successfully uninstalled thinc-6.10.3\n",
      "  Found existing installation: spacy 2.0.12\n",
      "    Uninstalling spacy-2.0.12:\n",
      "      Successfully uninstalled spacy-2.0.12\n",
      "  Found existing installation: fastprogress 0.1.9\n",
      "    Uninstalling fastprogress-0.1.9:\n",
      "      Successfully uninstalled fastprogress-0.1.9\n",
      "  Found existing installation: fastai 1.0.4\n",
      "    Uninstalling fastai-1.0.4:\n",
      "      Successfully uninstalled fastai-1.0.4\n",
      "Successfully installed cymem-2.0.2 fastai-1.0.6 fastprogress-0.1.10 preshed-2.0.1 regex-2018.1.10 spacy-2.0.16 thinc-6.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai==1.0.6\n",
    "from fastai import *        # Quick access to most common functionality\n",
    "from fastai.text import *   # Quick access to NLP functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of creating a language model and then transfering to a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_mount = '/floyd/input/imdb_reviews/'\n",
    "wt103_mount = '/floyd/input/wt103_v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/\n",
    "def build_directory_from_mounts(src='/floyd/input/imdb_reviews_wt103', dst='data/', sample_size=1000):\n",
    "    \"\"\"\n",
    "    Copy mounted directory into writable local, then overwrite training language model csv with the specified sample_size\n",
    "    \"\"\"\n",
    "    shutil.copytree(src, dst)\n",
    "    dftr_lm = read_csv_with_sample_size(\n",
    "        dst+'train.csv', sample_size=sample_size)\n",
    "    dftr_lm.to_csv(dst+'train_lm.csv', index=False)\n",
    "build_directory_from_mounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_with_sample_size(path, sample_size=10, chunksize=24000):\n",
    "  total_rows = get_total_length(path, chunksize=chunksize)\n",
    "  frac = sample_size/total_rows\n",
    "  df = pd.DataFrame()\n",
    "  for chunk in pd.read_csv(path, chunksize=chunksize, header=None):\n",
    "    df = pd.concat([df,chunk.sample(frac=frac)])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>0</td>\n",
       "      <td>Maggie is a widow in her fifties living in a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13857</th>\n",
       "      <td>0</td>\n",
       "      <td>I am appalled to see that so many people have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>0</td>\n",
       "      <td>Barney is about \"IMAGINATION\" what you guys do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>0</td>\n",
       "      <td>Good characters, well paced, with a tight scri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12366</th>\n",
       "      <td>0</td>\n",
       "      <td>This movie tackled closure, which is probably ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "11849  0  Maggie is a widow in her fifties living in a s...\n",
       "13857  0  I am appalled to see that so many people have ...\n",
       "2765   0  Barney is about \"IMAGINATION\" what you guys do...\n",
       "577    0  Good characters, well paced, with a tight scri...\n",
       "12366  0  This movie tackled closure, which is probably ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftr = read_csv_with_sample_size(imdb_mount+'train.csv', sample_size=1000)\n",
    "dftr_clas = pd.read_csv(dir_path+'train_clas.csv', header=None)\n",
    "dftr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/csv')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('data')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr.to_csv(path/'train.csv', index=False)\n",
    "dftr_clas.to_csv(path/'train_clas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and view the independent and dependent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Maggie is a widow in her fifties living in a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I am appalled to see that so many people have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Barney is about \"IMAGINATION\" what you guys do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Good characters, well paced, with a tight scri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0                                                  1\n",
       "1  0  Maggie is a widow in her fifties living in a s...\n",
       "2  0  I am appalled to see that so many people have ...\n",
       "3  0  Barney is about \"IMAGINATION\" what you guys do...\n",
       "4  0  Good characters, well paced, with a tight scri..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = read_classes(path/'classes.txt')[:2]\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `DataBunch` for each of the language model and the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing train.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='0.00% [0/1 00:00<00:00]')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericalizing train.\n",
      "Tokenizing valid.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='0.00% [0/1 00:00<00:00]')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericalizing valid.\n",
      "Tokenizing train_clas.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='0.00% [0/1 00:00<00:00]')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericalizing train_clas.\n",
      "Tokenizing valid_clas.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='0.00% [0/3 00:00<00:00]')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericalizing valid_clas.\n"
     ]
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_csv(path, train=\"train_lm\")\n",
    "data_clas = TextClasDataBunch.from_csv(path, train='train_clas', valid='valid_clas', vocab=data_lm.train_ds.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[fast.ai](http://www.fast.ai/) has a pre-trained English model available that we can download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb      imdb_clas\tmodels\ttrain.csv\tvalid.csv\n",
      "classes.txt  imdb_lm\ttmp\ttrain_clas.csv\tvalid_clas.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fine-tune the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=2), HTML(value='0.00% [0/2 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 03:41\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      4.896679    4.185995    0.244655  (01:50)\n",
      "1      4.635169    4.129789    0.249731  (01:50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = RNNLearner.language_model(data_lm, pretrained_fnames=['lstm_wt103', 'itos_wt103'])\n",
    "learn.unfreeze()\n",
    "learn.fit(2, slice(1e-4,1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our language model's encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder(f'enc{len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune it to create a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=3), HTML(value='0.00% [0/3 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 10:48\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      0.651802    0.645724    0.612720  (03:36)\n",
      "1      0.635723    0.566419    0.717680  (03:36)\n",
      "2      0.632057    0.566731    0.705840  (03:35)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = RNNLearner.classifier(data_clas)\n",
    "learn.load_encoder(f'enc{len(df)}')\n",
    "learn.fit(3, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder(f'enc_clas{len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
